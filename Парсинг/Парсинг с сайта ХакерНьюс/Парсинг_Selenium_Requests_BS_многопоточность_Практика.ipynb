{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDzAa_qNVOKL"
      },
      "source": [
        "### Загрузим библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o-5cpC2VOKZ"
      },
      "outputs": [],
      "source": [
        "#!pip install selenium\n",
        "\n",
        "import datetime\n",
        "from time import sleep, time\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjB-85klVOKi"
      },
      "source": [
        "### Объявим константы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4Hk_HOSVOKk"
      },
      "outputs": [],
      "source": [
        "filename = \"articles_info.csv\" # имя файла, в который будем сохранять результат\n",
        "driver_path = \"/home/user/Selenium/chromedriver\" # путь к chromedriver\n",
        "base_dir= \"/home/user/Selenium/parse/\" # укажем директорию, в которую будем сохранять файл\n",
        "user_agent = \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0\" # мой user-agent, взятый на сайте: https://юзерагент.рф, смотреть через браузер Chrome\n",
        "start_time = time() # время начала выполнения программы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5VH4WgIVOKm"
      },
      "source": [
        "### Зададим несколько вспомогательных функций.\n",
        "#### Функция get_load_time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-bnjwWTVOKn"
      },
      "outputs": [],
      "source": [
        "def get_load_time(article_url, user_agent):\n",
        "    \"\"\"Функция для подсчета времени для загрузки каждой новостной веб-страницы (статьи).\n",
        "        В дальнейшем он может использоваться, например, при планировании времени обхода страниц.\n",
        "\n",
        "    Args:\n",
        "        article_url (URL): адрес в интернете, где располагается спарсиваемая статья\n",
        "        user_agent (text): строка в запросе с информацией о версии ОС, браузера и устройстве.\n",
        "    Returns:\n",
        "        int: время загрузки страницы\n",
        "    \"\"\"\n",
        "    # будем ждать 3 секунды, иначе выводить exception и присваивать константное значение\n",
        "    try:\n",
        "        # меняем значение заголовка. По умолчанию указано, что это python-код\n",
        "        headers = {\n",
        "            \"User-Agent\": user_agent\n",
        "        }\n",
        "        # делаем запрос по url статьи article_url\n",
        "        response = requests.get(\n",
        "            article_url, headers=headers, stream=True, timeout=3.000\n",
        "        )\n",
        "        # получаем время загрузки страницы\n",
        "        load_time = response.elapsed.total_seconds()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        load_time = \">3\"\n",
        "    return load_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WA7pCvdVOKr"
      },
      "source": [
        "### Функция write_to_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9xUrc-oVOKv"
      },
      "outputs": [],
      "source": [
        "def write_to_file(output_list, filename, base_dir):\n",
        "    \"\"\"Функция для сохранения результатов парсинга в файл.\n",
        "\n",
        "    Args:\n",
        "        output_list (list): Список с информацией о спарсиваемых статьях\n",
        "        filename (text): Имя файла, в который будем сохранять результат\n",
        "        base_dir (path): Директория, в которую будем сохранять файл\n",
        "    \"\"\"\n",
        "    for row in output_list:\n",
        "        with open(Path(base_dir).joinpath(filename), \"a\") as csvfile:\n",
        "            fieldnames = [\"id\", \"load_time\", \"rank\", \"points\", \"title\", \"url\", \"num_comments\"]\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPLFgOrqVOKx"
      },
      "source": [
        "### Функция authorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lBNwl96VOKz"
      },
      "outputs": [],
      "source": [
        "def authorization(browser):\n",
        "    \"\"\"Функция для прохождения авторизации на сайте, с которого происходит парсинг\n",
        "\n",
        "    Args:\n",
        "        browser (WebDriver): Элемент класса WebDriver\n",
        "\n",
        "    Returns:\n",
        "        bool: Переменная показывает, успешно ли прошла авторизация\n",
        "        \"\"\"\n",
        "    base_url = \"https://news.ycombinator.com\"\n",
        "    for connection_attempts in range(1,4): # совершаем 3 попытки подключения\n",
        "        try:\n",
        "            browser.get(base_url)\n",
        "            #дождемся появления кнопки \"login\", и нажмем её\n",
        "            # затем функция вернет True иначе False\n",
        "            button = WebDriverWait(browser, 20).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, '/html/body/center/table/tbody/tr[1]/td/table/tbody/tr/td[3]/span/a')))\n",
        "            button.click()\n",
        "\n",
        "            # убедимся, необходимые поля готово для ввода и введем логин и пароль\n",
        "            username = WebDriverWait(browser, 20).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '/html/body/form[1]/table/tbody/tr[1]/td[2]/input')))\n",
        "            username.send_keys('piioner')\n",
        "\n",
        "            password = WebDriverWait(browser, 20).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '/html/body/form[1]/table/tbody/tr[2]/td[2]/input')))\n",
        "            password.send_keys('5hOeTtDB')\n",
        "\n",
        "            # осуществим ввод логина и пароля\n",
        "            login_button = WebDriverWait(browser, 20).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, '/html/body/form[1]/input[2]')))\n",
        "            login_button.click()\n",
        "            # в случае успеха функция вернёт True\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"Error connecting to {}.\".format(base_url))\n",
        "            print(\"Attempt #{}.\".format(connection_attempts))\n",
        "    # в случае неуспеха функция вернёт False\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehrMGH7JVOK1"
      },
      "source": [
        "### Функция connect_to_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1KNS_F_VOK2"
      },
      "outputs": [],
      "source": [
        "def connect_to_base(browser, page_number):\n",
        "    \"\"\"Прежде чем брать данные с открытой в Selenium страницы, необходимо некоторое время для загрузки на страницу контента.\n",
        "       Эта функция ожидает загрузку таблицы на страницу некоторое время и возвращает TRUE в случае её доступности.\n",
        "       WebDriverWait говорит Selenium ждать, пока не выполнится некоторое условие (пока таблица не подгрузится).\n",
        "\n",
        "    Args:\n",
        "        browser (WebDriver): Элемент класса WebDriver\n",
        "        page_number (int): Номер динамической страницы\n",
        "\n",
        "    Returns:\n",
        "        _Bool: Информация о том, что загрузка страницы произведена(True) или нет(False).\n",
        "    \"\"\"\n",
        "    base_url = \"https://news.ycombinator.com/news?p={}\".format(page_number)\n",
        "    for connection_attempts in range(1,4): # совершаем 3 попытки подключения\n",
        "        try:\n",
        "            browser.get(base_url)\n",
        "            # ожидаем пока элемент table с id = 'hnmain' будет загружен на страницу\n",
        "            # затем функция вернет True иначе False\n",
        "            WebDriverWait(browser, 5).until(\n",
        "                EC.presence_of_element_located((By.ID, \"hnmain\"))\n",
        "            )\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"Error connecting to {}.\".format(base_url))\n",
        "            print(\"Attempt #{}.\".format(connection_attempts))\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JL6u7mqVOK3"
      },
      "source": [
        "### Функция parse_html()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcE39QLxVOK4"
      },
      "outputs": [],
      "source": [
        "def parse_html(html, user_agent):\n",
        "    \"\"\"В этой функции мы будем парсить страницу с Beautiful Soup,\n",
        "        извлекая необходимые атрибуты и записывая их в список.\n",
        "\n",
        "    Args:\n",
        "        html (URL): Спарсиваемая страница\n",
        "        user_agent (text): Строка в запросе с информацией о версии ОС, браузера и устройстве.\n",
        "\n",
        "    Returns:\n",
        "        list: Список с информацией о спарсиваемых статьях\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    output_list = []\n",
        "\n",
        "    # ищем в объекте soup object id, rank, score и title статьи\n",
        "    tr_blocks = soup.find_all(\"tr\", class_=\"athing\")\n",
        "    article = 0\n",
        "    for tr in tr_blocks:\n",
        "        article_id = tr.get(\"id\") # id\n",
        "        article_url = tr.find_all(\"a\")[1][\"href\"]\n",
        "\n",
        "        # иногда статья располагается не на внешнем сайте, а на ycombinator\n",
        "        # тогда article_url у нее не полный, а добавочный, с параметрами.\n",
        "        # например item?id=200933. Для этих случаев будем добавлять url до полного\n",
        "        if \"item?id=\" in article_url or \"from?site=\" in article_url:\n",
        "            article_url = f\"https://news.ycombinator.com/{article_url}\"\n",
        "        load_time = get_load_time(article_url, user_agent)\n",
        "        # иногда рейтинга может не быть, поэтому воспользуемся try\n",
        "\n",
        "        try:\n",
        "            score = soup.find(id=f\"score_{article_id}\").string\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            score = \"0 points\"\n",
        "\n",
        "        try:\n",
        "            attr_value = f\"item?id={article_id}\"\n",
        "            comments = soup.find_all('a', {'href': attr_value})[1].string.split()\n",
        "            num_comments=\" \".join(comments)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            comments = \"0 comments\"\n",
        "\n",
        "        article_info = {\n",
        "            \"id\": article_id,\n",
        "            \"load_time\": load_time,\n",
        "            \"rank\": tr.span.string,\n",
        "            \"points\": score,\n",
        "            \"title\": tr.select(\"span>a:nth-child(1)\")[0].text,\n",
        "            \"url\": article_url,\n",
        "            \"num_comments\": num_comments\n",
        "        }\n",
        "\n",
        "        # добавляем информацию о статье в список\n",
        "        output_list.append(article_info)\n",
        "        article += 1\n",
        "    return output_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kn-or__VOK6"
      },
      "source": [
        "## Многопоточность\n",
        "\n",
        "Запустим многопоточность, немного изменив наш основной код — вынесем его в отдельную функцию и будем запускать её в потоке:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vqdLpkvVOK7",
        "outputId": "aa263db8-f24b-4efa-add2-e7e02b9d6d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Авторизация пройдена\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPSConnectionPool(host='www.cs.rpi.edu', port=443): Max retries exceeded with url: /academics/courses/spring11/proglang/handouts/lambda-calculus-chapter.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
            "HTTPConnectionPool(host='localhost', port=47541): Max retries exceeded with url: /session/3ecfc25b3f7f27149d76493e704662bb/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8a6405cd90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Error connecting to https://news.ycombinator.com/news?p=8.\n",
            "Attempt #1.\n",
            "HTTPConnectionPool(host='localhost', port=47541): Max retries exceeded with url: /session/3ecfc25b3f7f27149d76493e704662bb/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8a395b7370>: Failed to establish a new connection: [Errno 111] Connection refused'))HTTPConnectionPool(host='localhost', port=47541): Max retries exceeded with url: /session/3ecfc25b3f7f27149d76493e704662bb/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8a39266a30>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Error connecting to https://news.ycombinator.com/news?p=8.\n",
            "\n",
            "Error connecting to https://news.ycombinator.com/news?p=9.\n",
            "Attempt #1.\n",
            "Attempt #2.\n",
            "HTTPConnectionPool(host='localhost', port=47541): Max retries exceeded with url: /session/3ecfc25b3f7f27149d76493e704662bb/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8a39266e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Error connecting to https://news.ycombinator.com/news?p=9.\n",
            "Attempt #2.\n",
            "HTTPConnectionPool(host='localhost', port=47541): Max retries exceeded with url: /session/3ecfc25b3f7f27149d76493e704662bb/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8a392666d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Error connecting to https://news.ycombinator.com/news?p=8.\n",
            "Attempt #3.\n",
            "Error connecting to hacker news\n",
            "HTTPConnectionPool(host='localhost', port=47541): Max retries exceeded with url: /session/3ecfc25b3f7f27149d76493e704662bb/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8a6405c430>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Error connecting to https://news.ycombinator.com/news?p=9.\n",
            "Attempt #3.\n",
            "Error connecting to hacker news\n",
            "Elapsed run time: 67.32022285461426 seconds\n"
          ]
        }
      ],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, wait\n",
        "\n",
        "browser = webdriver.Chrome(\n",
        "        service=ChromeService(executable_path=driver_path)\n",
        "    )\n",
        "\n",
        "#Пройдем авторизацию\n",
        "if authorization(browser):\n",
        "    print('Авторизация пройдена')\n",
        "else:\n",
        "    print('Авторизация не пройдена')\n",
        "\n",
        "# Обернём процедуру парсинга страницы в функцию\n",
        "def run_process(browser, page_number, filename):\n",
        "    \"\"\"Функция автоматизирующая парсинг страницы\n",
        "\n",
        "    Args:\n",
        "        browser (WebDrive):Элемент класса WebDriver\n",
        "        page_number (int): Номер динамической страницы\n",
        "        filename (text): Имя файла, в который будем сохранять результат\n",
        "    \"\"\"\n",
        "    if connect_to_base(browser, page_number):\n",
        "        sleep(5)\n",
        "        output_list = parse_html(browser.page_source, user_agent)\n",
        "        write_to_file(output_list, filename, base_dir)\n",
        "\n",
        "        browser.quit()\n",
        "    else:\n",
        "        print(\"Error connecting to hacker news\")\n",
        "        browser.quit()\n",
        "\n",
        "# Глобальные переменные\n",
        "filename = \"articles_info.csv\" # имя файла, в который будем сохранять результат\n",
        "driver_path = \"/home/user/Selenium/chromedriver\" # путь к chromedriver\n",
        "base_dir= \"/home/user/Selenium/parse/\" # укажем директорию, в которую будем сохранять файл\n",
        "user_agent = \"Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/116.0\" # мой user-agent, взятый на сайте: https://юзерагент.рф, смотреть через браузер Chrome\n",
        "\n",
        "# Засечём время выполнения кода\n",
        "start_time = time()\n",
        "\n",
        "futures = []\n",
        "\n",
        "# Запустим процесс парсинга на нескольких потоках одновременно\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    for number in range(10):\n",
        "        futures.append(\n",
        "            executor.submit(run_process, browser, number, filename)\n",
        "        )\n",
        "\n",
        "wait(futures)\n",
        "end_time = time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed run time: {} seconds\".format(elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdcrdmm1VOK-"
      },
      "source": [
        "Чтобы подражать человеку-пользователю, вызывается метод sleep(5),<br>\n",
        "который вносит задержку на 5 секунд после того, как драйвер подключился к Hacker News.<br>\n",
        "После загрузки страницы и выполнения sleep(5) драйвер захватывает HTML-код страницы, <br>\n",
        "который затем передаётся в функцию parse_html().<br>\n",
        "\n",
        "В результате выполнения кода будет создан файл articles_info.csv, <br>\n",
        "который будет содержать всю информацию, которую мы спарсили. <br>\n",
        "Мы можем прочитать этот файл и представить таблицу в виде DataFrame:<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffqtnqeKVOLA",
        "outputId": "8d4db981-f2a0-4120-dee0-2591ac060be7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>load_time</th>\n",
              "      <th>rank</th>\n",
              "      <th>points</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37167922</td>\n",
              "      <td>6.525357</td>\n",
              "      <td>151.0</td>\n",
              "      <td>72 points</td>\n",
              "      <td>How the Army tried and failed to build a bicyc...</td>\n",
              "      <td>https://www.armytimes.com/news/your-army/2020/...</td>\n",
              "      <td>63 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37157811</td>\n",
              "      <td>0.73784</td>\n",
              "      <td>152.0</td>\n",
              "      <td>127 points</td>\n",
              "      <td>Acronym’s new computer with Asus is bonkers, b...</td>\n",
              "      <td>https://techcrunch.com/2023/08/16/review-acron...</td>\n",
              "      <td>165 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37179094</td>\n",
              "      <td>0.443781</td>\n",
              "      <td>153.0</td>\n",
              "      <td>223 points</td>\n",
              "      <td>Police are getting DNA data from people who th...</td>\n",
              "      <td>https://theintercept.com/2023/08/18/gedmatch-d...</td>\n",
              "      <td>179 comments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37193250</td>\n",
              "      <td>1.337712</td>\n",
              "      <td>154.0</td>\n",
              "      <td>8 points</td>\n",
              "      <td>BSD Now – Episode 520 “4 months BSD”</td>\n",
              "      <td>https://www.bsdnow.tv/520</td>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37167922</td>\n",
              "      <td>6.553725</td>\n",
              "      <td>151.0</td>\n",
              "      <td>72 points</td>\n",
              "      <td>How the Army tried and failed to build a bicyc...</td>\n",
              "      <td>https://www.armytimes.com/news/your-army/2020/...</td>\n",
              "      <td>63 comments</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id load_time   rank      points  \\\n",
              "0  37167922  6.525357  151.0   72 points   \n",
              "1  37157811   0.73784  152.0  127 points   \n",
              "2  37179094  0.443781  153.0  223 points   \n",
              "3  37193250  1.337712  154.0    8 points   \n",
              "4  37167922  6.553725  151.0   72 points   \n",
              "\n",
              "                                               title  \\\n",
              "0  How the Army tried and failed to build a bicyc...   \n",
              "1  Acronym’s new computer with Asus is bonkers, b...   \n",
              "2  Police are getting DNA data from people who th...   \n",
              "3               BSD Now – Episode 520 “4 months BSD”   \n",
              "4  How the Army tried and failed to build a bicyc...   \n",
              "\n",
              "                                                 url  num_comments  \n",
              "0  https://www.armytimes.com/news/your-army/2020/...   63 comments  \n",
              "1  https://techcrunch.com/2023/08/16/review-acron...  165 comments  \n",
              "2  https://theintercept.com/2023/08/18/gedmatch-d...  179 comments  \n",
              "3                          https://www.bsdnow.tv/520       discuss  \n",
              "4  https://www.armytimes.com/news/your-army/2020/...   63 comments  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "articles_data = pd.read_csv(\n",
        "    '/home/user/Selenium/parse/articles_info.csv',\n",
        "    names=[\"id\", \"load_time\", \"rank\", \"points\", \"title\", \"url\", \"num_comments\"],\n",
        "    encoding='utf-8'\n",
        ")\n",
        "\n",
        "articles_data.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}